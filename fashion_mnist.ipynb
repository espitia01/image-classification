{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "LQ05wvVIqjAI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l9H2eVBrBmZ",
        "outputId": "e0e0cd02-f56e-4e84-dbc9-3cfcf94d3b1d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    return self.linear_relu_stack(x)"
      ],
      "metadata": {
        "id": "9KfUWI47sJDG"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkyBTfCJvkSD",
        "outputId": "f15a724d-4080-4fe6-b04f-cbe00e09f29f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "WvXpLzUxxAXp"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = torchvision.datasets.FashionMNIST(root=\"/\", train = True, download = True, transform = transforms.ToTensor())\n",
        "testing_data = torchvision.datasets.FashionMNIST(root=\"/\", train = False, download = True, transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "N3QAPlrn0u8Z"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = torch.utils.data.DataLoader(testing_data, batch_size=64)"
      ],
      "metadata": {
        "id": "rp0YqIkk1hXt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    #forward\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad(): #freezes the parameters\n",
        "    for X, y in dataloader:\n",
        "      y_pred = model(X)\n",
        "      test_loss += loss_fn(y_pred, y).item()\n",
        "      correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  test_loss /= size\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "32O0weea2AqE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch: {epoch+1}\\n---------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI4nuEc62f9P",
        "outputId": "ae07e889-2b2b-4ca1-a5c8-a3326d3fd4ec"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "---------------------------\n",
            "loss: 0.817515  [    0/60000]\n",
            "loss: 1.010970  [ 6400/60000]\n",
            "loss: 0.943630  [12800/60000]\n",
            "loss: 1.292563  [19200/60000]\n",
            "loss: 1.270513  [25600/60000]\n",
            "loss: 1.296304  [32000/60000]\n",
            "loss: 1.190465  [38400/60000]\n",
            "loss: 1.169772  [44800/60000]\n",
            "loss: 1.071999  [51200/60000]\n",
            "loss: 1.449088  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.3%, Avg loss: 0.018730 \n",
            "\n",
            "Epoch: 2\n",
            "---------------------------\n",
            "loss: 0.793312  [    0/60000]\n",
            "loss: 1.008465  [ 6400/60000]\n",
            "loss: 0.949494  [12800/60000]\n",
            "loss: 1.273909  [19200/60000]\n",
            "loss: 1.265860  [25600/60000]\n",
            "loss: 1.281920  [32000/60000]\n",
            "loss: 1.184747  [38400/60000]\n",
            "loss: 1.143161  [44800/60000]\n",
            "loss: 1.083885  [51200/60000]\n",
            "loss: 1.440551  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 0.018681 \n",
            "\n",
            "Epoch: 3\n",
            "---------------------------\n",
            "loss: 0.794106  [    0/60000]\n",
            "loss: 1.003451  [ 6400/60000]\n",
            "loss: 0.950270  [12800/60000]\n",
            "loss: 1.265421  [19200/60000]\n",
            "loss: 1.266934  [25600/60000]\n",
            "loss: 1.273716  [32000/60000]\n",
            "loss: 1.175570  [38400/60000]\n",
            "loss: 1.120235  [44800/60000]\n",
            "loss: 1.078418  [51200/60000]\n",
            "loss: 1.439243  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 0.018649 \n",
            "\n",
            "Epoch: 4\n",
            "---------------------------\n",
            "loss: 0.791027  [    0/60000]\n",
            "loss: 1.000018  [ 6400/60000]\n",
            "loss: 0.950164  [12800/60000]\n",
            "loss: 1.259931  [19200/60000]\n",
            "loss: 1.258748  [25600/60000]\n",
            "loss: 1.265325  [32000/60000]\n",
            "loss: 1.169627  [38400/60000]\n",
            "loss: 1.105737  [44800/60000]\n",
            "loss: 1.071296  [51200/60000]\n",
            "loss: 1.435017  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.1%, Avg loss: 0.018627 \n",
            "\n",
            "Epoch: 5\n",
            "---------------------------\n",
            "loss: 0.791615  [    0/60000]\n",
            "loss: 0.991613  [ 6400/60000]\n",
            "loss: 0.952485  [12800/60000]\n",
            "loss: 1.255254  [19200/60000]\n",
            "loss: 1.254544  [25600/60000]\n",
            "loss: 1.260599  [32000/60000]\n",
            "loss: 1.164342  [38400/60000]\n",
            "loss: 1.089535  [44800/60000]\n",
            "loss: 1.065295  [51200/60000]\n",
            "loss: 1.429318  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.2%, Avg loss: 0.018609 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./model.pth\")\n",
        "\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b94NT_MY4qnP",
        "outputId": "8ae1a38b-9ec4-4a67-eb31-822fc3542c97"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can export our model as a Open Neural Network Exchange Model to train once and perform inference in other hardward and languages."
      ],
      "metadata": {
        "id": "IcTyOCL4CDEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8pN5vBmCO1a",
        "outputId": "695ee17a-652d-43b6-b0a7-cf3b975807bf"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx as onnx\n",
        "input_image = torch.zeros(image.shape)"
      ],
      "metadata": {
        "id": "RMOM9tIxCX5W"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpLnJ1sfDMSE",
        "outputId": "d5f9abd9-9642-4516-81bd-ca6327466388"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = \"./model.onnx\"\n",
        "onnx.export(model, input_image, onnx_model)"
      ],
      "metadata": {
        "id": "eTK8EiQQCoPI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.FashionMNIST(root=\"/\", train = True, transform = transforms.ToTensor())"
      ],
      "metadata": {
        "id": "3hvl6O1JDKgd"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "image, label = test_data[0]"
      ],
      "metadata": {
        "id": "MERou7GyDoGE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhTu15EbDw84",
        "outputId": "a4cd7652-7612-41d6-b6bf-a3fd6a9acd9d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime"
      ],
      "metadata": {
        "id": "NzrFXaz7EHpg"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = onnxruntime.InferenceSession(onnx_model, None)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "result = session.run([output_name], {input_name: image.numpy()})\n",
        "predicted, actual = classes[result[0][0].argmax(0)], classes[label]\n",
        "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPTC9uy1ES5p",
        "outputId": "eb1124da-d163-4134-c632-067f73e9c081"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"T-shirt/top\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWo48o9MEiXW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}